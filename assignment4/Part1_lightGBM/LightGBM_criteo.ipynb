{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from lightgbm_utils.ipynb\n",
      "System version: 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\n",
      "LightGBM version: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from tempfile import TemporaryDirectory\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "import import_ipynb\n",
    "import lightgbm_utils as lgb_utils\n",
    "#import reco_utils.dataset.criteo as criteo\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"LightGBM version: {}\".format(lgb.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEAF = 64\n",
    "MIN_DATA = 20\n",
    "NUM_OF_TREES = 100\n",
    "TREE_LEARNING_RATE = 0.15\n",
    "EARLY_STOPPING_ROUNDS = 20\n",
    "METRIC = \"auc\"\n",
    "SIZE = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_class': 1,\n",
    "    'objective': \"binary\",\n",
    "    'metric': METRIC,\n",
    "    'num_leaves': MAX_LEAF,\n",
    "    'min_data': MIN_DATA,\n",
    "    'boost_from_average': True,\n",
    "    #set it according to your cpu cores.\n",
    "    'num_threads': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'learning_rate': TREE_LEARNING_RATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import math\n",
    "import zipfile\n",
    "from contextlib import contextmanager\n",
    "from tempfile import TemporaryDirectory\n",
    "from tqdm import tqdm\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def maybe_download(url, filename=None, work_directory=\".\", expected_bytes=None):\n",
    "   \n",
    "    if filename is None:\n",
    "        filename = url.split(\"/\")[-1]\n",
    "    os.makedirs(work_directory, exist_ok=True)\n",
    "    filepath = os.path.join(work_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "\n",
    "        r = requests.get(url, stream=True)\n",
    "        total_size = int(r.headers.get(\"content-length\", 0))\n",
    "        block_size = 1024\n",
    "        num_iterables = math.ceil(total_size / block_size)\n",
    "\n",
    "        with open(filepath, \"wb\") as file:\n",
    "            for data in tqdm(\n",
    "                r.iter_content(block_size),\n",
    "                total=num_iterables,\n",
    "                unit=\"KB\",\n",
    "                unit_scale=True,\n",
    "            ):\n",
    "                file.write(data)\n",
    "    else:\n",
    "        log.info(\"File {} already downloaded\".format(filepath))\n",
    "    if expected_bytes is not None:\n",
    "        statinfo = os.stat(filepath)\n",
    "        if statinfo.st_size != expected_bytes:\n",
    "            os.remove(filepath)\n",
    "            raise IOError(\"Failed to verify {}\".format(filepath))\n",
    "\n",
    "    return filepath\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def download_path(path=None):\n",
    "    \"\"\"Return a path to download data. If `path=None`, then it yields a temporal path that is eventually deleted, \n",
    "    otherwise the real path of the input. \n",
    "    Args:\n",
    "        path (str): Path to download data.\n",
    "    Returns:\n",
    "        str: Real path where the data is stored.\n",
    "    Examples:\n",
    "        >>> with download_path() as path:\n",
    "        >>> ... maybe_download(url=\"http://example.com/file.zip\", work_directory=path)\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        tmp_dir = TemporaryDirectory()\n",
    "        try:\n",
    "            yield tmp_dir.name\n",
    "        finally:\n",
    "            tmp_dir.cleanup()\n",
    "    else:\n",
    "        path = os.path.realpath(path)\n",
    "        yield path\n",
    "\n",
    "\n",
    "def unzip_file(zip_src, dst_dir, clean_zip_file=True):\n",
    "    \"\"\"Unzip a file\n",
    "    Args:\n",
    "        zip_src (str): Zip file.\n",
    "        dst_dir (str): Destination folder.\n",
    "        clean_zip_file (bool): Whether or not to clean the zip file.\n",
    "    \"\"\"\n",
    "    fz = zipfile.ZipFile(zip_src, \"r\")\n",
    "    for file in fz.namelist():\n",
    "        fz.extract(file, dst_dir)\n",
    "    if clean_zip_file:\n",
    "        os.remove(zip_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "try:\n",
    "    from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "except ImportError:\n",
    "    pass  # so the environment without spark doesn't break\n",
    "\n",
    "#from reco_utils.dataset.download_utils import maybe_download, download_path\n",
    "#from reco_utils.common.notebook_utils import is_databricks\n",
    "\n",
    "\n",
    "CRITEO_URL = {\n",
    "    \"full\": \"https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz\",\n",
    "    \"sample\": \"http://labs.criteo.com/wp-content/uploads/2015/04/dac_sample.tar.gz\",\n",
    "}\n",
    "DEFAULT_HEADER = (\n",
    "    [\"label\"]\n",
    "    + [\"int{0:02d}\".format(i) for i in range(13)]\n",
    "    + [\"cat{0:02d}\".format(i) for i in range(26)]\n",
    ")\n",
    "\n",
    "\n",
    "def load_pandas_df(size=\"sample\", local_cache_path=None, header=DEFAULT_HEADER):\n",
    "    \n",
    "    with download_path(local_cache_path) as path:\n",
    "        filepath = download_criteo(size, path)\n",
    "        filepath = extract_criteo(size, filepath)\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\", header=None, names=header)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_spark_df(\n",
    "    spark,\n",
    "    size=\"sample\",\n",
    "    header=DEFAULT_HEADER,\n",
    "    local_cache_path=None,\n",
    "    dbfs_datapath=\"dbfs:/FileStore/dac\",\n",
    "    dbutils=None,\n",
    "):\n",
    "  \n",
    "    with download_path(local_cache_path) as path:\n",
    "        filepath = download_criteo(size, path)\n",
    "        filepath = extract_criteo(size, filepath)\n",
    "\n",
    "        if is_databricks():\n",
    "            try:\n",
    "                # Driver node's file path\n",
    "                node_path = \"file:\" + filepath\n",
    "                ## needs to be on dbfs to load\n",
    "                dbutils.fs.cp(node_path, dbfs_datapath, recurse=True)\n",
    "                path = dbfs_datapath\n",
    "            except:\n",
    "                raise ValueError(\n",
    "                    \"To use on a Databricks notebook, dbutils object should be passed as an argument\"\n",
    "                )\n",
    "        else:\n",
    "            path = filepath\n",
    "\n",
    "        schema = get_spark_schema(header)\n",
    "        df = spark.read.csv(path, schema=schema, sep=\"\\t\", header=False)\n",
    "        df.cache().count()  # trigger execution to overcome spark's lazy evaluation\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_criteo(size=\"sample\", work_directory=\".\"):\n",
    "    \"\"\"Download criteo dataset as a compressed file.\n",
    "    Args:\n",
    "        size (str): Size of criteo dataset. It can be \"full\" or \"sample\".\n",
    "        work_directory (str): Working directory.\n",
    "    Returns:\n",
    "        str: Path of the downloaded file.\n",
    "    \"\"\"\n",
    "    url = CRITEO_URL[size]\n",
    "    return maybe_download(url, work_directory=work_directory)\n",
    "\n",
    "\n",
    "def extract_criteo(size, compressed_file, path=None):\n",
    "    \"\"\"Extract Criteo dataset tar.\n",
    "    Args:\n",
    "        size (str): Size of Criteo dataset. It can be \"full\" or \"sample\".\n",
    "        compressed_file (str): Path to compressed file.\n",
    "        path (str): Path to extract the file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the extracted file.\n",
    "    \n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        folder = os.path.dirname(compressed_file)\n",
    "        extracted_dir = os.path.join(folder, \"dac\")\n",
    "    else:\n",
    "        extracted_dir = path\n",
    "\n",
    "    with tarfile.open(compressed_file) as tar:\n",
    "        tar.extractall(extracted_dir)\n",
    "\n",
    "    filename_selector = {\"sample\": \"dac_sample.txt\", \"full\": \"train.txt\"}\n",
    "    return os.path.join(extracted_dir, filename_selector[size])\n",
    "\n",
    "\n",
    "def get_spark_schema(header=DEFAULT_HEADER):\n",
    "    ## create schema\n",
    "    schema = StructType()\n",
    "    ## do label + ints\n",
    "    n_ints = 14\n",
    "    for i in range(n_ints):\n",
    "        schema.add(StructField(header[i], IntegerType()))\n",
    "    ## do categoricals\n",
    "    for i in range(26):\n",
    "        schema.add(StructField(header[i + n_ints], StringType()))\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8.58k/8.58k [00:03<00:00, 2.83kKB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b5194c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c5c50484</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>9727dd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label   I1   I2    I3    I4      I5    I6    I7   I8     I9  ...       C17  \\\n",
       "0      0  1.0    1   5.0   0.0  1382.0   4.0  15.0  2.0  181.0  ...  e5ba7672   \n",
       "1      0  2.0    0  44.0   1.0   102.0   8.0   2.0  2.0    4.0  ...  07c540c4   \n",
       "2      0  2.0    0   1.0  14.0   767.0  89.0   4.0  2.0  245.0  ...  8efede7f   \n",
       "3      0  NaN  893   NaN   NaN  4392.0   NaN   0.0  0.0    0.0  ...  1e88c74f   \n",
       "4      0  3.0   -1   NaN   0.0     2.0   0.0   3.0  0.0    0.0  ...  1e88c74f   \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24  \\\n",
       "0  f54016b9  21ddcdc9  b1252a9d  07b5194c       NaN  3a171ecb  c5c50484   \n",
       "1  b04e4670  21ddcdc9  5840adea  60f6221e       NaN  3a171ecb  43f13e8b   \n",
       "2  3412118d       NaN       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c   \n",
       "3  74ef3502       NaN       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a   \n",
       "4  26b3c7a7       NaN       NaN  21c9516a       NaN  32c7478e  b34f3128   \n",
       "\n",
       "        C25       C26  \n",
       "0  e8b83407  9727dd16  \n",
       "1  e8b83407  731c3655  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from dataload import maybe_download, download_path, load_pandas_df, load_spark_df, download_criteo,extract_criteo\n",
    "\n",
    "nume_cols = [\"I\" + str(i) for i in range(1, 14)]\n",
    "cate_cols = [\"C\" + str(i) for i in range(1, 27)]\n",
    "label_col = \"Label\"\n",
    "\n",
    "header = [label_col] + nume_cols + cate_cols\n",
    "with TemporaryDirectory() as tmp:\n",
    "    all_data = load_pandas_df(size=SIZE, local_cache_path=tmp, header=header)\n",
    "display(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv (r'C:\\Users\\kaviy\\Desktop\\Assignment4\\Part1_lightGBM\\criteo_data.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to 3 sets    \n",
    "length = len(all_data)\n",
    "train_data = all_data.loc[:0.8*length-1]\n",
    "valid_data = all_data.loc[0.8*length:0.9*length-1]\n",
    "test_data = all_data.loc[0.9*length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: X: (80000, 39); Y: (80000,).\n",
      "Valid Data Shape: X: (10000, 39); Y: (10000,).\n",
      "Test Data Shape: X: (10000, 39); Y: (10000,).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    I1   I2    I3    I4      I5    I6    I7   I8     I9  I10  ...  C17  C18  \\\n",
       "0  1.0    1   5.0   0.0  1382.0   4.0  15.0  2.0  181.0  1.0  ...    1    1   \n",
       "1  2.0    0  44.0   1.0   102.0   8.0   2.0  2.0    4.0  1.0  ...    2    2   \n",
       "2  2.0    0   1.0  14.0   767.0  89.0   4.0  2.0  245.0  1.0  ...    3    3   \n",
       "3  NaN  893   NaN   NaN  4392.0   NaN   0.0  0.0    0.0  NaN  ...    4    4   \n",
       "4  3.0   -1   NaN   0.0     2.0   0.0   3.0  0.0    0.0  1.0  ...    4    5   \n",
       "\n",
       "   C19  C20  C21  C22  C23  C24  C25  C26  \n",
       "0    1    1    1    1    1    1    1    1  \n",
       "1    1    2    2    1    1    2    1    2  \n",
       "2    2    3    3    2    1    3    2    3  \n",
       "3    2    3    4    1    1    4    2    3  \n",
       "4    2    3    5    1    2    5    2    3  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_encoder = ce.ordinal.OrdinalEncoder(cols=cate_cols)\n",
    "\n",
    "def encode_csv(df, encoder, label_col, typ='fit'):\n",
    "    if typ == 'fit':\n",
    "        df = encoder.fit_transform(df)\n",
    "    else:\n",
    "        df = encoder.transform(df)\n",
    "    y = df[label_col].values\n",
    "    del df[label_col]\n",
    "    return df, y\n",
    "\n",
    "train_x, train_y = encode_csv(train_data, ord_encoder, label_col)\n",
    "valid_x, valid_y = encode_csv(valid_data, ord_encoder, label_col, 'transform')\n",
    "test_x, test_y = encode_csv(test_data, ord_encoder, label_col, 'transform')\n",
    "\n",
    "print('Train Data Shape: X: {trn_x_shape}; Y: {trn_y_shape}.\\nValid Data Shape: X: {vld_x_shape}; Y: {vld_y_shape}.\\nTest Data Shape: X: {tst_x_shape}; Y: {tst_y_shape}.\\n'\n",
    "      .format(trn_x_shape=train_x.shape,\n",
    "              trn_y_shape=train_y.shape,\n",
    "              vld_x_shape=valid_x.shape,\n",
    "              vld_y_shape=valid_y.shape,\n",
    "              tst_x_shape=test_x.shape,\n",
    "              tst_y_shape=test_y.shape,))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17958, number of negative: 62042\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38971\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224475 -> initscore=-1.239776\n",
      "[LightGBM] [Info] Start training from score -1.239776\n",
      "[1]\tvalid_0's auc: 0.723997\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.736596\n",
      "[3]\tvalid_0's auc: 0.740862\n",
      "[4]\tvalid_0's auc: 0.745639\n",
      "[5]\tvalid_0's auc: 0.74944\n",
      "[6]\tvalid_0's auc: 0.751076\n",
      "[7]\tvalid_0's auc: 0.752973\n",
      "[8]\tvalid_0's auc: 0.753746\n",
      "[9]\tvalid_0's auc: 0.7546\n",
      "[10]\tvalid_0's auc: 0.755247\n",
      "[11]\tvalid_0's auc: 0.7565\n",
      "[12]\tvalid_0's auc: 0.756926\n",
      "[13]\tvalid_0's auc: 0.757582\n",
      "[14]\tvalid_0's auc: 0.757758\n",
      "[15]\tvalid_0's auc: 0.758596\n",
      "[16]\tvalid_0's auc: 0.75866\n",
      "[17]\tvalid_0's auc: 0.759058\n",
      "[18]\tvalid_0's auc: 0.759658\n",
      "[19]\tvalid_0's auc: 0.759656\n",
      "[20]\tvalid_0's auc: 0.758798\n",
      "[21]\tvalid_0's auc: 0.759329\n",
      "[22]\tvalid_0's auc: 0.759307\n",
      "[23]\tvalid_0's auc: 0.759538\n",
      "[24]\tvalid_0's auc: 0.758459\n",
      "[25]\tvalid_0's auc: 0.758257\n",
      "[26]\tvalid_0's auc: 0.758256\n",
      "[27]\tvalid_0's auc: 0.757745\n",
      "[28]\tvalid_0's auc: 0.757413\n",
      "[29]\tvalid_0's auc: 0.757701\n",
      "[30]\tvalid_0's auc: 0.757612\n",
      "[31]\tvalid_0's auc: 0.757312\n",
      "[32]\tvalid_0's auc: 0.75732\n",
      "[33]\tvalid_0's auc: 0.756654\n",
      "[34]\tvalid_0's auc: 0.756381\n",
      "[35]\tvalid_0's auc: 0.756279\n",
      "[36]\tvalid_0's auc: 0.756333\n",
      "[37]\tvalid_0's auc: 0.756346\n",
      "[38]\tvalid_0's auc: 0.756381\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.759658\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_x, train_y.reshape(-1), params=params, categorical_feature=cate_cols)\n",
    "lgb_valid = lgb.Dataset(valid_x, valid_y.reshape(-1), reference=lgb_train, categorical_feature=cate_cols)\n",
    "lgb_test = lgb.Dataset(test_x, test_y.reshape(-1), reference=lgb_train, categorical_feature=cate_cols)\n",
    "lgb_model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=NUM_OF_TREES,\n",
    "                      early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                      valid_sets=lgb_valid,\n",
    "                      categorical_feature=cate_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7655408801711783, 'logloss': 0.4682583178835999}\n"
     ]
    }
   ],
   "source": [
    "test_preds = lgb_model.predict(test_x)\n",
    "auc = roc_auc_score(np.asarray(test_y.reshape(-1)), np.asarray(test_preds))\n",
    "logloss = log_loss(np.asarray(test_y.reshape(-1)), np.asarray(test_preds), eps=1e-12)\n",
    "res_basic = {\"auc\": auc, \"logloss\": logloss}\n",
    "print(res_basic)\n",
    "#pm.record(\"res_basic\", res_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Usage\n",
    "### Label-encoding and Binary-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-10 15:47:50,024 [INFO] Filtering and fillna features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 15.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 466.76it/s]\n",
      "2020-11-10 15:47:51,727 [INFO] Ordinal encoding cate features\n",
      "2020-11-10 15:47:52,645 [INFO] Target encoding cate features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:04<00:00,  6.26it/s]\n",
      "2020-11-10 15:47:56,804 [INFO] Start manual binary encoding\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:03<00:00, 19.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:02<00:00,  9.64it/s]\n",
      "2020-11-10 15:48:02,996 [INFO] Filtering and fillna features\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 229.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 3249.65it/s]\n",
      "2020-11-10 15:48:03,121 [INFO] Ordinal encoding cate features\n",
      "2020-11-10 15:48:03,189 [INFO] Target encoding cate features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 50.90it/s]\n",
      "2020-11-10 15:48:03,704 [INFO] Start manual binary encoding\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 23.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 19.87it/s]\n",
      "2020-11-10 15:48:07,908 [INFO] Filtering and fillna features\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 253.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 2623.08it/s]\n",
      "2020-11-10 15:48:08,024 [INFO] Ordinal encoding cate features\n",
      "2020-11-10 15:48:08,117 [INFO] Target encoding cate features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 53.77it/s]\n",
      "2020-11-10 15:48:08,604 [INFO] Start manual binary encoding\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 23.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: X: (80000, 268); Y: (80000, 1).\n",
      "Valid Data Shape: X: (10000, 268); Y: (10000, 1).\n",
      "Test Data Shape: X: (10000, 268); Y: (10000, 1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_col = 'Label'\n",
    "num_encoder = lgb_utils.NumEncoder(cate_cols, nume_cols, label_col)\n",
    "train_x, train_y = num_encoder.fit_transform(train_data)\n",
    "valid_x, valid_y = num_encoder.transform(valid_data)\n",
    "test_x, test_y = num_encoder.transform(test_data)\n",
    "del num_encoder\n",
    "print('Train Data Shape: X: {trn_x_shape}; Y: {trn_y_shape}.\\nValid Data Shape: X: {vld_x_shape}; Y: {vld_y_shape}.\\nTest Data Shape: X: {tst_x_shape}; Y: {tst_y_shape}.\\n'\n",
    "      .format(trn_x_shape=train_x.shape,\n",
    "              trn_y_shape=train_y.shape,\n",
    "              vld_x_shape=valid_x.shape,\n",
    "              vld_y_shape=valid_y.shape,\n",
    "              tst_x_shape=test_x.shape,\n",
    "              tst_y_shape=test_y.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17958, number of negative: 62042\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15787\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 267\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224475 -> initscore=-1.239776\n",
      "[LightGBM] [Info] Start training from score -1.239776\n",
      "[1]\tvalid_0's auc: 0.727035\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.745243\n",
      "[3]\tvalid_0's auc: 0.749993\n",
      "[4]\tvalid_0's auc: 0.750781\n",
      "[5]\tvalid_0's auc: 0.753203\n",
      "[6]\tvalid_0's auc: 0.754548\n",
      "[7]\tvalid_0's auc: 0.756143\n",
      "[8]\tvalid_0's auc: 0.757718\n",
      "[9]\tvalid_0's auc: 0.758371\n",
      "[10]\tvalid_0's auc: 0.759261\n",
      "[11]\tvalid_0's auc: 0.760498\n",
      "[12]\tvalid_0's auc: 0.761402\n",
      "[13]\tvalid_0's auc: 0.762118\n",
      "[14]\tvalid_0's auc: 0.762916\n",
      "[15]\tvalid_0's auc: 0.764051\n",
      "[16]\tvalid_0's auc: 0.764829\n",
      "[17]\tvalid_0's auc: 0.76559\n",
      "[18]\tvalid_0's auc: 0.766304\n",
      "[19]\tvalid_0's auc: 0.766337\n",
      "[20]\tvalid_0's auc: 0.767213\n",
      "[21]\tvalid_0's auc: 0.767702\n",
      "[22]\tvalid_0's auc: 0.767753\n",
      "[23]\tvalid_0's auc: 0.768076\n",
      "[24]\tvalid_0's auc: 0.768541\n",
      "[25]\tvalid_0's auc: 0.768448\n",
      "[26]\tvalid_0's auc: 0.769026\n",
      "[27]\tvalid_0's auc: 0.769197\n",
      "[28]\tvalid_0's auc: 0.769597\n",
      "[29]\tvalid_0's auc: 0.769688\n",
      "[30]\tvalid_0's auc: 0.769907\n",
      "[31]\tvalid_0's auc: 0.769919\n",
      "[32]\tvalid_0's auc: 0.769846\n",
      "[33]\tvalid_0's auc: 0.77005\n",
      "[34]\tvalid_0's auc: 0.770085\n",
      "[35]\tvalid_0's auc: 0.77021\n",
      "[36]\tvalid_0's auc: 0.770272\n",
      "[37]\tvalid_0's auc: 0.76992\n",
      "[38]\tvalid_0's auc: 0.770547\n",
      "[39]\tvalid_0's auc: 0.770695\n",
      "[40]\tvalid_0's auc: 0.77068\n",
      "[41]\tvalid_0's auc: 0.770748\n",
      "[42]\tvalid_0's auc: 0.770631\n",
      "[43]\tvalid_0's auc: 0.77085\n",
      "[44]\tvalid_0's auc: 0.770606\n",
      "[45]\tvalid_0's auc: 0.770498\n",
      "[46]\tvalid_0's auc: 0.770594\n",
      "[47]\tvalid_0's auc: 0.770367\n",
      "[48]\tvalid_0's auc: 0.770168\n",
      "[49]\tvalid_0's auc: 0.770126\n",
      "[50]\tvalid_0's auc: 0.770045\n",
      "[51]\tvalid_0's auc: 0.769959\n",
      "[52]\tvalid_0's auc: 0.770195\n",
      "[53]\tvalid_0's auc: 0.770192\n",
      "[54]\tvalid_0's auc: 0.770075\n",
      "[55]\tvalid_0's auc: 0.770156\n",
      "[56]\tvalid_0's auc: 0.769972\n",
      "[57]\tvalid_0's auc: 0.769837\n",
      "[58]\tvalid_0's auc: 0.769985\n",
      "[59]\tvalid_0's auc: 0.770135\n",
      "[60]\tvalid_0's auc: 0.770282\n",
      "[61]\tvalid_0's auc: 0.770291\n",
      "[62]\tvalid_0's auc: 0.77022\n",
      "[63]\tvalid_0's auc: 0.770291\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.77085\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_x, train_y.reshape(-1), params=params)\n",
    "lgb_valid = lgb.Dataset(valid_x, valid_y.reshape(-1), reference=lgb_train)\n",
    "lgb_model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=NUM_OF_TREES,\n",
    "                      early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                      valid_sets=lgb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7758548016657666, 'logloss': 0.46030887404896165}\n"
     ]
    }
   ],
   "source": [
    "test_preds = lgb_model.predict(test_x)\n",
    "auc = roc_auc_score(np.asarray(test_y.reshape(-1)), np.asarray(test_preds))\n",
    "logloss = log_loss(np.asarray(test_y.reshape(-1)), np.asarray(test_preds), eps=1e-12)\n",
    "res_optim = {\"auc\": auc, \"logloss\": logloss}\n",
    "print(res_optim)\n",
    "#pm.record(\"res_optim\", res_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7758548016657666, 'logloss': 0.46030887404896165}\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as tmp:\n",
    "    save_file = os.path.join(tmp, r'finished.model')\n",
    "    lgb_model.save_model(save_file)\n",
    "    loaded_model = lgb.Booster(model_file=save_file)\n",
    "\n",
    "# eval the performance again\n",
    "test_preds = loaded_model.predict(test_x)\n",
    "\n",
    "auc = roc_auc_score(np.asarray(test_y.reshape(-1)), np.asarray(test_preds))\n",
    "logloss = log_loss(np.asarray(test_y.reshape(-1)), np.asarray(test_preds), eps=1e-12)\n",
    "print({\"auc\": auc, \"logloss\": logloss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
